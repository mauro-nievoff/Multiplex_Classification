{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root = 'path to the root folder'\n",
    "images_folder = root + 'subpath to the folder with the images'\n",
    "save_path = root + 'models/'\n",
    "table_path = root + 'subpath to hyperkvasir_multiplex.csv'\n",
    "splits_path = root + 'subpath to hyperkvasir_splits.csv'\n",
    "\n",
    "# Settings\n",
    "use_oversampling = False # select True or False\n",
    "submodel_type = 'pathological-findings' # select one of [pathological-findings, pathological-findings:Lower GI, pathological-findings:Lower GI.ulcerative-colitis, pathological-findings:Upper GI, pathological-findings:Upper GI.barrets-unspecific, pathological-findings:Upper GI.esophagitis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import albumentations\n",
    "from DLOlympus.training.transforms import AlbumentationsTransform\n",
    "from DLOlympus.training.utils import get_model\n",
    "from DLOlympus.training.unbalanced import oversampled_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "h, w = 224, 224\n",
    "\n",
    "hyperparameters = {\n",
    "    'model_description': submodel_type,\n",
    "    'BS': 16,\n",
    "    'EPOCHS': 30,\n",
    "    'IMG_SIZE': (h, w),      # (height, width)\n",
    "    'WD': 0.0,\n",
    "    'TRANSFORMS': [\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.Rotate(p=0.5),\n",
    "        albumentations.Sharpen(p=0.5),\n",
    "        albumentations.ColorJitter(brightness=0.3, contrast=0.5, saturation=0.5, hue=0.0, p=0.5),\n",
    "        albumentations.RGBShift(p=0.5),\n",
    "        albumentations.GaussianBlur(p=0.5),\n",
    "        albumentations.GaussNoise(p=0.5),\n",
    "        albumentations.RandomSizedCrop((int(0.75*h),h), h, w, p=1.0)\n",
    "        ],\n",
    "    'ARCH': 'resnet50',\n",
    "    'ARCH_TYPE': 'torchvision',\n",
    "    'LOSS_FUNC': 'LabelSmoothingCrossEntropyFlat',\n",
    "    'OPT_FUNC': 'Adam',\n",
    "    'USE_OVERSAMPLING': use_oversampling,\n",
    "    'SEED': 18,\n",
    "}\n",
    "\n",
    "# Metrics and callbacks\n",
    "metrics = [accuracy, F1Score(average='macro')]\n",
    "callbacks = [SaveModelCallback(monitor='f1_score', with_opt=True), ShowGraphCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data(table_path, splits_path):\n",
    "    # Read data\n",
    "    data = pd.read_csv(table_path)\n",
    "    # Get relevant info\n",
    "    image_files = images_folder+data['file'].values\n",
    "    labels = data[hyperparameters['model_description']].values\n",
    "    splits = pd.read_csv(splits_path)['is_valid'].values\n",
    "    use_ids = [type(d) == str for d in labels]\n",
    "    return image_files[use_ids], labels[use_ids], splits[use_ids]\n",
    "\n",
    "def create_df(image_files, labels, splits):\n",
    "    # Initiate dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['file_path'] = image_files\n",
    "    df['label'] = labels\n",
    "    # Add a binary column to the dataframe\n",
    "    df['is_valid'] = splits\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "image_files, labels, splits = get_data(table_path, splits_path)\n",
    "df = create_df(image_files, labels, splits)\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(hyperparameters['SEED'], True)\n",
    "\n",
    "# Datablock\n",
    "block = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_x=ColReader('file_path'),\n",
    "    get_y=ColReader('label'),\n",
    "    splitter=ColSplitter(col='is_valid'),\n",
    "    item_tfms=[\n",
    "        Resize(hyperparameters['IMG_SIZE'], method='squish'), \n",
    "        AlbumentationsTransform(albumentations.Compose(hyperparameters['TRANSFORMS']))])\n",
    "\n",
    "# Dataloaders\n",
    "dls = block.dataloaders(df, bs=hyperparameters['BS'], shuffle=True)\n",
    "dls.rng.seed(hyperparameters['SEED'])\n",
    "\n",
    "# Sanity check\n",
    "num_classes = dls.c\n",
    "classes = dls.vocab\n",
    "print('Number of clases: ', num_classes)\n",
    "print('Names of classes: ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show batch\n",
    "dls.train.show_batch(max_n=16, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transforms\n",
    "dls.train.show_batch(max_n=16, unique=True, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner\n",
    "learn = vision_learner(dls,\n",
    "                        get_model(hyperparameters),\n",
    "                        normalize=True,\n",
    "                        pretrained=True,\n",
    "                        loss_func=getattr(sys.modules[__name__], hyperparameters['LOSS_FUNC'])(),\n",
    "                        opt_func=getattr(sys.modules[__name__], hyperparameters['OPT_FUNC']),\n",
    "                        metrics=metrics,\n",
    "                        wd=hyperparameters['WD']).to_fp16()\n",
    "\n",
    "# Fix issue with pickling while calling learn.export\n",
    "import typing, functools\n",
    "learn.loss_func.func.__annotations__ = typing.get_type_hints(learn.loss_func.func, globalns=globals(), localns=locals())\n",
    "functools.update_wrapper(learn.loss_func, learn.loss_func.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "if hyperparameters['USE_OVERSAMPLING']:\n",
    "    learn.dls.train.get_idxs = types.MethodType(oversampled_epoch, learn.dls.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find LR\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LR\n",
    "hyperparameters['LR'] = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "learn.fine_tune(hyperparameters['EPOCHS'], base_lr=hyperparameters['LR'], cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(f'{save_path}/model.pkl')\n",
    "learn.save(f'{save_path}/model')\n",
    "\n",
    "from DLOlympus.training.plots import plot_confusion_matrix, plot_losses, plot_metrics\n",
    "_ = plot_losses(learn, save_path)\n",
    "_ = plot_metrics(learn, save_path)\n",
    "probs, ground_truths = learn.get_preds(ds_idx=1)        # DO NOT PREDICT BEFORE PLOTTING LOSSES AND METRICS\n",
    "predictions = np.argmax(probs, axis=1)\n",
    "_ = plot_confusion_matrix(ground_truths, predictions, learn.dls.vocab, save_path)\n",
    "\n",
    "from DLOlympus.training.tables import get_predictions_table\n",
    "train_table = get_predictions_table(learn, learn.dls.train)\n",
    "valid_table = get_predictions_table(learn, learn.dls.valid)\n",
    "train_table.to_csv(f'{save_path}train_table.csv', index=False)\n",
    "valid_table.to_csv(f'{save_path}valid_table.csv', index=False)\n",
    "\n",
    "from DLOlympus.training.utils import get_metrics\n",
    "results = get_metrics(learn, with_tta=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multicare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
