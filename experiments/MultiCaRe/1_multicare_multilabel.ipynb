{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root = 'path to the root folder'\n",
    "images_folder = root + 'subpath to the folder with the images'\n",
    "save_path = root + 'models/'\n",
    "table_path = root + 'subpath to multicare_multiplex.csv'\n",
    "\n",
    "# Settings\n",
    "use_oversampling = False # select True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import albumentations\n",
    "from DLOlympus.training.transforms import AlbumentationsTransform\n",
    "from DLOlympus.training.utils import get_model\n",
    "from DLOlympus.training.unbalanced import oversampled_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "radiology_ids = torch.Tensor([7, 9, 22, 24, 28])\n",
    "angiography_ids = torch.Tensor([2, 23])\n",
    "\n",
    "mapping = {\n",
    "    (2, 7): 29,\n",
    "    (7, 23): 30,\n",
    "    (2, 9): 31,\n",
    "    (9, 23): 32,\n",
    "    (2, 22): 33,\n",
    "    (22, 23): 34,\n",
    "    (2, 24): 35,\n",
    "    (23, 24): 36,\n",
    "    (2, 28): 37,\n",
    "    (23, 28): 38\n",
    "}\n",
    "\n",
    "def new_classes(x):\n",
    "    # Convert input tensor to a tuple of integers\n",
    "    key = tuple(x.int().tolist())\n",
    "    # Return the mapped value or default to the first element of x\n",
    "    return mapping.get(key, int(x[0].item()))\n",
    "\n",
    "def multilabel2multiclass(probs, ground_truths):\n",
    "    probs = probs.cpu()\n",
    "    ground_truths = ground_truths.cpu()\n",
    "    new_preds = []\n",
    "    new_gts = []\n",
    "    for p, gt in zip(probs, ground_truths):\n",
    "        # Get the id of the top prediction\n",
    "        pred = p.argmax()\n",
    "        # Check if the id corresponds to any of the dual classes\n",
    "        is_ang = pred in angiography_ids\n",
    "        is_rad = pred in radiology_ids\n",
    "        # If angiography type is predicted, get radiology type prediction\n",
    "        if is_ang:\n",
    "            pred = torch.stack((pred, radiology_ids[p[radiology_ids.int()].argmax()]))\n",
    "        # If radiology type is predicted, get angiography type prediction\n",
    "        elif is_rad:\n",
    "            pred = torch.stack((pred, angiography_ids[p[angiography_ids.int()].argmax()]))\n",
    "        else:\n",
    "            pred = pred[None]\n",
    "        # Convert indices to the new format\n",
    "        pred, _ = torch.sort(pred)\n",
    "        pred = new_classes(pred)\n",
    "        gt, _ = torch.sort(gt.nonzero())\n",
    "        gt = new_classes(gt[:,0])\n",
    "        new_preds.append(pred)\n",
    "        new_gts.append(gt)\n",
    "    # print(np.array(new_preds), np.array(new_gts))\n",
    "    return torch.Tensor(new_preds), torch.Tensor(new_gts)\n",
    "\n",
    "def new_accuracy(probs, ground_truths):\n",
    "    predictions, ground_truths = multilabel2multiclass(probs, ground_truths)\n",
    "    return (predictions == ground_truths).float().mean()\n",
    "\n",
    "def _accumulate(self, learn):\n",
    "    m = nn.Sigmoid()\n",
    "    pred = learn.pred\n",
    "    targ = learn.y\n",
    "    pred,targ = to_detach(pred),to_detach(targ)\n",
    "    pred, targ = multilabel2multiclass(pred, targ)\n",
    "    self.preds.append(pred)\n",
    "    self.targs.append(targ)\n",
    "AccumMetric.accumulate = _accumulate\n",
    "def NewF1Score():\n",
    "    return skm_to_fastai(f1_score, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "h, w = 224, 224\n",
    "\n",
    "hyperparameters = {\n",
    "    'model_description': 'multilabel',\n",
    "    'BS': 16,\n",
    "    'EPOCHS': 30,\n",
    "    'IMG_SIZE': (h, w),      # (height, width)\n",
    "    'WD': 0.0,\n",
    "    'TRANSFORMS': [\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.Rotate(p=0.5),\n",
    "        albumentations.Sharpen(p=0.5),\n",
    "        albumentations.ColorJitter(brightness=0.3, contrast=0.5, saturation=0.5, hue=0.0, p=0.5),\n",
    "        albumentations.RGBShift(p=0.5),\n",
    "        albumentations.GaussianBlur(p=0.5),\n",
    "        albumentations.GaussNoise(p=0.5),\n",
    "        albumentations.RandomSizedCrop((int(0.75*h),h), h, w, p=1.0)\n",
    "        ],\n",
    "    'ARCH': 'resnet50',\n",
    "    'ARCH_TYPE': 'torchvision',\n",
    "    'LOSS_FUNC': 'BCEWithLogitsLossFlat',\n",
    "    'OPT_FUNC': 'Adam',\n",
    "    'USE_OVERSAMPLING': use_oversampling,\n",
    "    'SEED': 18,\n",
    "}\n",
    "\n",
    "# Metrics and callbacks\n",
    "metrics = [new_accuracy, NewF1Score()]\n",
    "callbacks = [SaveModelCallback(monitor='f1_score', with_opt=True), ShowGraphCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "def get_gt(x):\n",
    "    # Convert string to list: discard extra characters and delete ultrasound label\n",
    "    return [s for s in x.split(\"'\") if len(s)>1 and ' ' not in s and s != 'ultrasound']\n",
    "\n",
    "def get_data(table_path):\n",
    "    # Read data\n",
    "    data = pd.read_csv(table_path)\n",
    "    # Get relevant info\n",
    "    image_files = np.array([f'{images_folder}{s[:4]}/{s[:6]}/{s}' for s in (data['file'].values)])\n",
    "    labels = data['label_list_with_negative_classes'].apply(get_gt)\n",
    "    groups = data['patient_id'].values\n",
    "    return image_files, labels, groups\n",
    "\n",
    "def create_df(image_files, labels, groups, n_splits=10, n_valid=2):\n",
    "    # Initiate dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['file_path'] = image_files\n",
    "    df['label'] = labels.values\n",
    "    df['groups'] = groups\n",
    "    df['fold'] = -1\n",
    "    # Make folds\n",
    "    cv = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    for i, (train_idxs, valid_idxs) in enumerate(cv.split(image_files, labels.apply(str), groups)):\n",
    "        df.loc[valid_idxs, ['fold']] = i\n",
    "    # Assign folds for validation\n",
    "    df['split'] = 'train'\n",
    "    for i in range (n_valid):\n",
    "        df.loc[df.fold == i, ['split']] = 'valid'\n",
    "    del df['fold']\n",
    "    df.split.value_counts()\n",
    "    # Add a binary column to the dataframe\n",
    "    df['is_valid'] = df.split == 'valid'\n",
    "    del df['split']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "image_files, labels, groups = get_data(table_path)\n",
    "df = create_df(image_files, labels, groups)\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(hyperparameters['SEED'], True)\n",
    "\n",
    "# Datablock\n",
    "block = DataBlock(\n",
    "    blocks=(ImageBlock, MultiCategoryBlock),\n",
    "    get_x=ColReader('file_path'),\n",
    "    get_y=ColReader('label'),\n",
    "    splitter=ColSplitter(col='is_valid'),\n",
    "    item_tfms=[\n",
    "        Resize(hyperparameters['IMG_SIZE'], method='squish'), \n",
    "        AlbumentationsTransform(albumentations.Compose(hyperparameters['TRANSFORMS']))])\n",
    "\n",
    "# Dataloaders\n",
    "dls = block.dataloaders(df, bs=hyperparameters['BS'], shuffle=True)\n",
    "dls.rng.seed(hyperparameters['SEED'])\n",
    "\n",
    "# Sanity check\n",
    "num_classes = dls.c\n",
    "classes = dls.vocab\n",
    "print('Number of clases: ', num_classes)\n",
    "print('Names of classes: ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show batch\n",
    "dls.train.show_batch(max_n=16, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transforms\n",
    "dls.train.show_batch(max_n=16, unique=True, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner\n",
    "learn = vision_learner(dls,\n",
    "                        get_model(hyperparameters),\n",
    "                        normalize=True,\n",
    "                        pretrained=True,\n",
    "                        loss_func=getattr(sys.modules[__name__], hyperparameters['LOSS_FUNC'])(),\n",
    "                        opt_func=getattr(sys.modules[__name__], hyperparameters['OPT_FUNC']),\n",
    "                        metrics=metrics,\n",
    "                        wd=hyperparameters['WD']).to_fp16()\n",
    "\n",
    "# Fix issue with pickling while calling learn.export\n",
    "import typing, functools\n",
    "learn.loss_func.func.__annotations__ = typing.get_type_hints(learn.loss_func.func, globalns=globals(), localns=locals())\n",
    "functools.update_wrapper(learn.loss_func, learn.loss_func.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "if hyperparameters['USE_OVERSAMPLING']:\n",
    "    class_weights = pd.DataFrame(1 / np.sqrt(learn.dls.items.label.value_counts())).rename(index=lambda x: str(x)).to_dict()['count']\n",
    "    learn.dls.train.get_idxs = types.MethodType(partial(oversampled_epoch, class_weights=class_weights), learn.dls.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find LR\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LR\n",
    "hyperparameters['LR'] = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "learn.fine_tune(hyperparameters['EPOCHS'], base_lr=hyperparameters['LR'], cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vocab(vocab): \n",
    "    vocab = list(copy(vocab))\n",
    "    # Add composed classes\n",
    "    for v in ['ct + angiography', 'ct + not_angiography', 'echocardiogram + angiography', 'echocardiogram + not_angiography', 'mri + angiography', 'mri + not_angiography', 'other_ultrasound + angiography', 'other_ultrasound + not_angiography', 'x_ray + angiography', 'x_ray + not_angiography']:\n",
    "        vocab.append(v)\n",
    "    # Delete single classes that are not needed\n",
    "    for index in sorted(list(np.array(np.concatenate((angiography_ids, radiology_ids)), dtype=int)), reverse=True):\n",
    "        del vocab[index]\n",
    "    return CategoryMap(vocab, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(f'{save_path}/model.pkl')\n",
    "learn.save(f'{save_path}/model')\n",
    "\n",
    "from DLOlympus.training.plots import plot_confusion_matrix, plot_losses, plot_metrics\n",
    "_ = plot_losses(learn, save_path)\n",
    "_ = plot_metrics(learn, save_path)\n",
    "probs, ground_truths = learn.get_preds(ds_idx=1)        # DO NOT PREDICT BEFORE PLOTTING LOSSES AND METRICS\n",
    "predictions, ground_truths_trans = multilabel2multiclass(probs, ground_truths)\n",
    "vocab = new_vocab(learn.dls.vocab)\n",
    "_ = plot_confusion_matrix(ground_truths_trans, predictions, vocab, save_path, figsize=(22,16))\n",
    "\n",
    "from DLOlympus.training.utils import get_metrics\n",
    "results = get_metrics(learn, with_tta=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multicare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
