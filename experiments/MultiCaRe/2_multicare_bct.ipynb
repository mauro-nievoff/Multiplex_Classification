{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root = 'path to the root folder'\n",
    "images_folder = root + 'subpath to the folder with the images'\n",
    "save_path = root + 'models/'\n",
    "table_path = root + 'subpath to multicare_multiplex.csv'\n",
    "splits_path = root + 'subpath to multicare_splits.csv'\n",
    "\n",
    "# Settings\n",
    "use_oversampling = False # select True or False\n",
    "submodel_type = 'imaging_type' # select one of [imaging_type, imaging_type:endoscopy, imaging_type:pathology, imaging_type:pathology.other_staining, imaging_type:radiology(main|attribute_angiography), imaging_type:radiology.ultrasound]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import albumentations\n",
    "from DLOlympus.training.transforms import AlbumentationsTransform\n",
    "from DLOlympus.training.utils import get_model\n",
    "from DLOlympus.training.unbalanced import oversampled_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "h, w = 224, 224\n",
    "\n",
    "hyperparameters = {\n",
    "    'model_description': submodel_type,\n",
    "    'BS': 16,\n",
    "    'EPOCHS': 30,\n",
    "    'IMG_SIZE': (h, w),      # (height, width)\n",
    "    'WD': 0.0,\n",
    "    'TRANSFORMS': [\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.Rotate(p=0.5),\n",
    "        albumentations.Sharpen(p=0.5),\n",
    "        albumentations.ColorJitter(brightness=0.3, contrast=0.5, saturation=0.5, hue=0.0, p=0.5),\n",
    "        albumentations.RGBShift(p=0.5),\n",
    "        albumentations.GaussianBlur(p=0.5),\n",
    "        albumentations.GaussNoise(p=0.5),\n",
    "        albumentations.RandomSizedCrop((int(0.75*h),h), h, w, p=1.0)\n",
    "        ],\n",
    "    'ARCH': 'resnet50',\n",
    "    'ARCH_TYPE': 'torchvision',\n",
    "    'LOSS_FUNC': 'LabelSmoothingCrossEntropyFlat',\n",
    "    'OPT_FUNC': 'Adam',\n",
    "    'USE_OVERSAMPLING': use_oversampling,\n",
    "    'SEED': 18,\n",
    "}\n",
    "\n",
    "# Metrics and callbacks\n",
    "metrics = [accuracy, F1Score(average='macro')]\n",
    "callbacks = [SaveModelCallback(monitor='f1_score', with_opt=True), ShowGraphCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data(table_path, splits_path):\n",
    "    # Read data\n",
    "    data = pd.read_csv(table_path)\n",
    "    # Get relevant info\n",
    "    image_files = np.array([f'{images_folder}{s[:4]}/{s[:6]}/{s}' for s in (data['file'].values)])\n",
    "    labels = data[hyperparameters['model_description']].values\n",
    "    splits = pd.read_csv(splits_path)['is_valid'].values\n",
    "    use_ids = [type(d) == str for d in labels]\n",
    "    return image_files[use_ids], labels[use_ids], splits[use_ids]\n",
    "\n",
    "def create_df(image_files, labels, splits):\n",
    "    # Initiate dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['file_path'] = image_files\n",
    "    df['label'] = labels\n",
    "    # Add a binary column to the dataframe\n",
    "    df['is_valid'] = splits\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "image_files, labels, splits = get_data(table_path, splits_path)\n",
    "df = create_df(image_files, labels, splits)\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(hyperparameters['SEED'], True)\n",
    "\n",
    "# Datablock\n",
    "if hyperparameters['model_description'] == 'imaging_type:radiology(main|attribute_angiography)':\n",
    "    def get_rad(x):\n",
    "        return [i[1:-1] for i in str(ColReader('label')(x))[1:-1].split(', ')][0]\n",
    "    def get_ang(x):\n",
    "        return [i[1:-1] for i in str(ColReader('label')(x))[1:-1].split(', ')][1]\n",
    "    block = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock, CategoryBlock),\n",
    "        n_inp=1,\n",
    "        get_x=ColReader('file_path'),\n",
    "        get_y=[get_rad, get_ang],\n",
    "        splitter=ColSplitter(col='is_valid'),\n",
    "        item_tfms=[\n",
    "            Resize(hyperparameters['IMG_SIZE'], method='squish'), \n",
    "            AlbumentationsTransform(albumentations.Compose(hyperparameters['TRANSFORMS']))])\n",
    "else:\n",
    "    block = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_x=ColReader('file_path'),\n",
    "        get_y=ColReader('label'),\n",
    "        splitter=ColSplitter(col='is_valid'),\n",
    "        item_tfms=[\n",
    "            Resize(hyperparameters['IMG_SIZE'], method='squish'), \n",
    "            AlbumentationsTransform(albumentations.Compose(hyperparameters['TRANSFORMS']))])\n",
    "    \n",
    "# Dataloaders\n",
    "dls = block.dataloaders(df, bs=hyperparameters['BS'], shuffle=True)\n",
    "dls.rng.seed(hyperparameters['SEED'])\n",
    "\n",
    "# Sanity check\n",
    "num_classes = dls.c\n",
    "classes = dls.vocab\n",
    "print('Number of clases: ', num_classes)\n",
    "print('Names of classes: ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show batch\n",
    "dls.train.show_batch(max_n=16, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transforms\n",
    "dls.train.show_batch(max_n=16, unique=True, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner\n",
    "if hyperparameters['model_description'] == 'imaging_type:radiology(main|attribute_angiography)':\n",
    "    def rad_loss(inp, rad, ang):\n",
    "        return getattr(sys.modules[__name__], hyperparameters['LOSS_FUNC'])()(inp[:,:dls.c[0]], rad)\n",
    "    def ang_loss(inp, rad, ang):\n",
    "        return getattr(sys.modules[__name__], hyperparameters['LOSS_FUNC'])()(inp[:,dls.c[0]:], ang)\n",
    "    def combined_loss(inp, rad, ang): return rad_loss(inp, rad, ang) + ang_loss(inp, rad, ang)   \n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "    mapping = {\n",
    "        (0, 0): 0,\n",
    "        (0, 1): 1,\n",
    "        (1, 0): 2,\n",
    "        (1, 1): 3,\n",
    "        (2, 0): 4,\n",
    "        (2, 1): 5,\n",
    "        (3, 0): 6,\n",
    "        (3, 1): 7\n",
    "    }\n",
    "    def new_classes(x):\n",
    "        # Convert input tensor to a tuple of integers\n",
    "        key = tuple(x.int().tolist())\n",
    "        # Return the mapped value or default to the first element of x\n",
    "        return mapping.get(key, int(x[0].item()))    \n",
    "    def multioutput2multiclass(probs, ground_truths_1, ground_truths_2):\n",
    "        probs = probs.cpu()\n",
    "        rad_probs = probs[:,:dls.c[0]]\n",
    "        ang_probs = probs[:,dls.c[0]:]\n",
    "        rad_truths, ang_truths = ground_truths_1.cpu(), ground_truths_2.cpu()\n",
    "        new_preds = []\n",
    "        new_gts = []\n",
    "        for rp, ap, rt, at in zip(rad_probs, ang_probs, rad_truths, ang_truths):\n",
    "            # Get the id of the top prediction\n",
    "            rad_pred, ang_pred = rp.argmax(), ap.argmax()\n",
    "            pred = new_classes(torch.stack((rad_pred, ang_pred)))\n",
    "            gt = new_classes(torch.stack((rt, at)))\n",
    "            new_preds.append(pred)\n",
    "            new_gts.append(gt)\n",
    "        return torch.Tensor(new_preds), torch.Tensor(new_gts)\n",
    "    def new_accuracy(probs, ground_truths_1, ground_truths_2):\n",
    "        predictions, ground_truths = multioutput2multiclass(probs, ground_truths_1, ground_truths_2)\n",
    "        return (predictions == ground_truths).float().mean()\n",
    "    def _accumulate(self, learn):\n",
    "        m = nn.Sigmoid()\n",
    "        pred = learn.pred\n",
    "        targ_1 = learn.y[0]\n",
    "        targ_2 = learn.y[1]\n",
    "        pred,targ_1,targ_2 = to_detach(pred),to_detach(targ_1),to_detach(targ_2)\n",
    "        pred,targ= multioutput2multiclass(pred, targ_1, targ_2)\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(targ)\n",
    "    AccumMetric.accumulate = _accumulate\n",
    "    def NewF1Score():\n",
    "        return skm_to_fastai(f1_score, average='macro')\n",
    "\n",
    "    learn = vision_learner(dls,\n",
    "                            get_model(hyperparameters),\n",
    "                            n_out=dls.c.sum(),\n",
    "                            normalize=True,\n",
    "                            pretrained=True,\n",
    "                            loss_func=combined_loss,\n",
    "                            opt_func=getattr(sys.modules[__name__], hyperparameters['OPT_FUNC']),\n",
    "                            metrics=[new_accuracy, NewF1Score()],\n",
    "                            wd=hyperparameters['WD']).to_fp16()\n",
    "    # Fix issue with pickling while calling learn.export\n",
    "    import typing, functools\n",
    "    learn.loss_func.__annotations__ = typing.get_type_hints(learn.loss_func, globalns=globals(), localns=locals())\n",
    "    functools.update_wrapper(learn.loss_func, learn.loss_func)    \n",
    "else:\n",
    "    learn = vision_learner(dls,\n",
    "                            get_model(hyperparameters),\n",
    "                            normalize=True,\n",
    "                            pretrained=True,\n",
    "                            loss_func=getattr(sys.modules[__name__], hyperparameters['LOSS_FUNC'])(weight=loss_weights),\n",
    "                            opt_func=getattr(sys.modules[__name__], hyperparameters['OPT_FUNC']),\n",
    "                            metrics=metrics,\n",
    "                            wd=hyperparameters['WD']).to_fp16()    \n",
    "    # Fix issue with pickling while calling learn.export\n",
    "    import typing, functools\n",
    "    learn.loss_func.func.__annotations__ = typing.get_type_hints(learn.loss_func.func, globalns=globals(), localns=locals())\n",
    "    functools.update_wrapper(learn.loss_func, learn.loss_func.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "if hyperparameters['USE_OVERSAMPLING']:\n",
    "    class_weights = pd.DataFrame(1 / np.sqrt(learn.dls.items.label.value_counts())).rename(index=lambda x: str(x)).to_dict()['count']\n",
    "    learn.dls.train.get_idxs = types.MethodType(partial(oversampled_epoch, class_weights=class_weights), learn.dls.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find LR\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LR\n",
    "hyperparameters['LR'] = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "learn.fine_tune(hyperparameters['EPOCHS'], base_lr=hyperparameters['LR'], cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(f'{save_path}/model.pkl')\n",
    "learn.save(f'{save_path}/model')\n",
    "\n",
    "from DLOlympus.training.plots import plot_confusion_matrix, plot_losses, plot_metrics\n",
    "_ = plot_losses(learn, save_path)\n",
    "_ = plot_metrics(learn, save_path)\n",
    "probs, ground_truths = learn.get_preds(ds_idx=1)        # DO NOT PREDICT BEFORE PLOTTING LOSSES AND METRICS\n",
    "if hyperparameters['model_description'] == 'imaging_type:radiology(main|attribute_angiography)':\n",
    "    predictions, ground_truths = multioutput2multiclass(probs, ground_truths[0], ground_truths[1])\n",
    "    _ = plot_confusion_matrix(ground_truths, predictions, ['ct + angiography', 'ct + not_angiography', 'mri + angiography', 'mri + not_angiography', 'ultrasound + angiography', 'ultrasound + not_angiography', 'x_ray + angiography', 'x_ray + not_angiography'], save_path)\n",
    "else:\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    _ = plot_confusion_matrix(ground_truths, predictions, learn.dls.vocab, save_path)\n",
    "    from DLOlympus.training.tables import get_predictions_table\n",
    "    train_table = get_predictions_table(learn, learn.dls.train)\n",
    "    valid_table = get_predictions_table(learn, learn.dls.valid)\n",
    "    train_table.to_csv(f'{save_path}train_table.csv', index=False)\n",
    "    valid_table.to_csv(f'{save_path}valid_table.csv', index=False)\n",
    "\n",
    "from DLOlympus.training.utils import get_metrics\n",
    "results = get_metrics(learn, with_tta=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multicare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
